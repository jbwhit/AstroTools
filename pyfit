#!/usr/bin/env python
# pyfit.py
# 
# The purpose of this program is to attempt to make fitting absorption systems 
# with vpfit reproducible, and easier. Several decisions were made that could
# be argued are steps in the wrong direction. Let me know if you have any better
# ideas or suggestions. (You can probably Google me and vpfit and find out my
# current information).
# 
# Copyright 2012 Jonathan Whitmore 
# Distributed under the Boost Software License, Version 1.0.
#
# Permission is hereby granted, free of charge, to any person or organization
# obtaining a copy of the software and accompanying documentation covered by
# this license (the "Software") to use, reproduce, display, distribute,
# execute, and transmit the Software, and to prepare derivative works of the
# Software, and to permit third-parties to whom the Software is furnished to
# do so, all subject to the following:
#
# The copyright notices in the Software and this entire statement, including
# the above license grant, this restriction and the following disclaimer,
# must be included in all copies of the Software, in whole or in part, and
# all derivative works of the Software, unless such copies or derivative
# works are solely in the form of machine-executable object code generated
# by a source language processor.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE AND
# NON-INFRINGEMENT. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR ANYONE
# DISTRIBUTING THE SOFTWARE BE LIABLE FOR ANY DAMAGES OR OTHER LIABILITY,
# WHETHER IN CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
# 

import argparse
import cPickle as pickle
from ConfigParser import SafeConfigParser
import csv
import datetime
import difflib
import glob
import heapq
import logging
import numpy as np
import os
import pprint
import readline
import re
import shutil
import simplejson as json
import string
import subprocess
import sys
import time 
import zlib

# Known limitations
# datafiles must not have spaces in their names.
# qa is the flag for fitting alpha.

latestAtomdat = 'MM_VPFIT_2012-06-05.dat' # Update this. 
fitLevelDict = {}
overview = {} # results dictionary

def main():
  overview['timeStamp'] = datetime.datetime.now().strftime("%Y-%m-%d_%H.%M.%S.%f")
  print overview['timeStamp']
  parser = argparse.ArgumentParser(description='Run vpfit with specified fitting parameters.')
  parser.add_argument('input13', action="store", nargs='?', default='fort.13', type=str) # Positional (feed in the fort.13-formatted file).
  parser.add_argument('--noComment', action="store_true", default=False, help='Turn off comment prompt.')
  parser.add_argument('--comment', action="store", default='', help='Give commandline comment.')
  parser.add_argument('--noPlot', action="store_true", default=False, help='Will not make pdf plots.')
  parser.add_argument('--bump', action="store_true", default=False, help='Will bump the fort.13 off the min values.')
  parser.add_argument('--fitType', action="store", default='normalFit', choices=('normalFit', 'normalFitAlphaFit', 'alphaFit', 'vchunkFit'), \
                      help='Choose pyfit behavior.')
  parser.add_argument('--maxRuns', action="store", default=1, type=int, help='Max runs before quitting. Setting to 1 means no restarts.')
  parser.add_argument('--vpfit', action="store", dest="vpfitVersion", default='9.5', type=str, help='Which version of vpfit to use.')
  parser.add_argument('--level', action="store", default='L5', type=str, \
                      help='Type in comma separated (no spaces) list of the order of the ways "leveling up" should go. ex: L2,L4,L5')
  parser.add_argument('--fitSetupDirectory', dest="fitSetupDirectory", default='notSet', help='Location of atom.dat, vp_setup.dat, etc.')
  parser.add_argument('--atomdat', choices=('isoAtomFile', 'atomFile'), default='atomFile', help='atom.dat choices')
  parser.add_argument('--version', action='version', version='%(prog)s 0.10''data file to use.') # Clearly not used.
  args = parser.parse_args()
  if args.vpfitVersion == ("9.5" or "95" or "vpfit9.5"):
    print "VPFIT version: ", args.vpfitVersion
    overview['vpfitExecutable'] = 'vpfit95'
  elif args.vpfitVersion == ("10.0" or "10" or "vpfit10.0"):
    print "VPFIT version: ", 
    overview['vpfitExecutable'] = 'vpfit10'
  else:
    print "What VPFIT version are you wanting to use?"
  tag = {}
  tag['normalFit'] = ''
  tag['alphaFit'] = '.alpha'
  tag['vchunkFit'] = '.vchunk'
  if args.fitType == 'normalFitAlphaFit':
    allowTransitiontoAlphaFit = True
    args.fitType = 'normalFit'    
  else:
    allowTransitiontoAlphaFit = False
    
  # =======================
  # = Begin pre-fit setup =
  # =======================

  overview['iterations125'] = False
  
  # Create fit directory
  os.makedirs(overview['timeStamp'])
  overview['parentDirectory'] = os.getcwd() + '/'
  os.chdir(overview['timeStamp'])
  overview['fitDirectory'] = os.getcwd() + '/'

  # Create a fitting log.
  logging.basicConfig(filename=overview['timeStamp'] + '.log', level=logging.DEBUG)
  for arg, value in sorted(vars(args).items()):
    logging.info("Argument %s: %r", arg, value)
    overview[arg] = value
  
  overview['maxRuns'] = int(args.maxRuns)
  
  configParser = SafeConfigParser()
  found = configParser.read(glob.glob(overview['parentDirectory'] + 'config*'))
  print "Using these config files:"
  for configfile in set(found):
    print "  ", configfile
    logging.info("config loaded: " + configfile)
  overview['configs'] = [x for x in set(found)]

  try:
    overview['gdriveKey'] = configParser.get('absorber','gdriveKey')
    overview['sheetNumber'] = configParser.get('absorber','sheetNumber')
    overview['QSO'] = configParser.get('absorber','QSO')
    overview['z_abs'] = configParser.get('absorber','z_abs')
  except:
    print "Missing out on google drive integration... use configs!"
    
  overview['setupDir'] = configParser.get('machine', 'setupdir') + '/'
  overview['atomDatFile'] = configParser.get('update', args.atomdat)
  shutil.copy(overview['setupDir'] + overview['atomDatFile'], overview['fitDirectory'])
  shutil.copy(overview['setupDir'] + 'vp_setup.dat', overview['fitDirectory'])
  shutil.copy(overview['setupDir'] + 'vp_splot.dat', overview['fitDirectory'])
  overview['dataDirectory'] = configParser.get('data', 'dataDirectory') + '/'
  os.symlink(overview['atomDatFile'], 'atom.dat') # create symbolic link to atom.dat in fitting directory.
  shutil.copy(overview['parentDirectory'] + args.input13, overview['fitDirectory'] + "input.fort.13")
  dataFiles = []
  with open("input.fort.13", 'r') as f13:
    beginHead, beginBody = False, False
    with open('head.6', 'w') as head, open('body.7', 'w') as body:
      for line in f13.read().splitlines():
        # Ignore comments and empty lines
        if (not line.strip().startswith('!') and (not line.strip().startswith('%')) and (line.strip() != '')): 
          if line.startswith('   *'):
            beginHead = True
          if beginHead == True:
            print >>head, line
            if len(line.split()) > 4:
              dataFiles.append(line.split()[0])
          if beginBody == True:
            print >>body, line
          if line.startswith('  *'):
            beginHead = False
            beginBody = True
  # combine head and body into fort.13
  cat('fort.13', 'head.6', 'body.7')
  overview['startingComponents'] = countLines('body.7')
  
  # parse the head to get data files used. 
  for datafile in set(dataFiles):
    os.symlink(overview['dataDirectory'] + datafile, overview['fitDirectory'] + datafile)
  overview['dataFiles'] = [x for x in set(dataFiles)]

  # Create dictionary of all level strings; use fitLevel as key.
  fitLevelDict["L1"] = "f\nil\ncs\n2.e-4 100.0 2.e-4\nn\n0.01 \nb\n0.2 \nz\n2.e-6\nx4\n5.e-6\n\n\nfort.13\nn\nn\n\n"
  fitLevelDict["L2"] = "f\nil\ncs\n2.e-5 100.0 2.e-5\nn\n0.005\nb\n0.1 \nz\n2.e-7\nx4\n5.e-6\n\n\nfort.13\nn\nn\n\n"
  fitLevelDict["L3"] = "f\nil\ncs\n2.e-6 100.0 2.e-6\nn\n0.002\nb\n0.05\nz\n2.e-7\nx4\n5.e-7\n\n\nfort.13\nn\nn\n\n"
  fitLevelDict["L4"] = "f\nil\ncs\n2.e-7 100.0 2.e-7\nn\n0.002\nb\n0.05\nz\n2.e-7\nx4\n5.e-7\n\n\nfort.13\nn\nn\n\n"
  fitLevelDict["L5"] = "f\nil\ncs\n1.e-8 100.0 1.e-8\nn\n0.002\nb\n0.05\nz\n2.e-7\nx4\n5.e-7\n\n\nfort.13\nn\nn\n\n"
  fitLevelDict["M6"] = "f\nil\ncs\n1.e-8 100.0 1.e-8\nn\n0.01 \nb\n0.1 \nz\n2.e-6\nx4\n5.e-6\n\n\nfort.13\nn\nn\n\n"
  fitLevelDict["M7"] = "f\nil\ncs\n1.e-7 100.0 1.e-7\nn\n0.01 \nb\n0.1 \nz\n2.e-6\nx4\n5.e-6\n\n\nfort.13\nn\nn\n\n"
  fitLevelDict["M8"] = "f\nil\ncs\n1.e-6 100.0 1.e-6\nn\n0.01 \nb\n0.1 \nz\n2.e-6\nx4\n5.e-6\n\n\nfort.13\nn\nn\n\n"

  
  levelIndex = 0
  levelList = []
  for x in args.level.split(','):
    levelList.append(x)
  levelString = fitLevelDict[levelList[levelIndex]] 
    
  # Create symbolic link of vpfit executable into fitting directory (for fitcmp purposes).
  overview['executableLink'] = subprocess.Popen(['which', overview['vpfitExecutable']], stdout=subprocess.PIPE)
  os.symlink(overview['executableLink'].communicate()[0].strip(), overview['fitDirectory'] + 'vpfit')
  overview['vpfitVersion'] = args.vpfitVersion
  
  # Change to use current directory settings. 
  os.environ['ATOMDIR'] = 'atom.dat'
  os.environ['VPFSETUP'] = 'vp_setup.dat'
  os.environ['VPFPLOTS'] = 'vp_splot.dat'
  overview['ATOMDIR'] = os.environ['ATOMDIR']
  overview['VPFSETUP'] = os.environ['VPFSETUP']
  overview['VPFPLOTS'] = os.environ['VPFPLOTS']
  
  # TODO make these the fort13flagcheck outputs get logged as errors/warnings in logger.
  # Parses the body of the body.7 for any anomalies.
  p = subprocess.call('fort13flagcheck') # waits for return.
  
  # Allows for comment (and check of output of the flag check)
  if (args.noComment == False) and (args.comment == ''):
    initialFitComment = raw_input("Comment: ")
    logging.info("Comment: " + initialFitComment)
    overview['comment'] = initialFitComment
  elif (args.noComment == False):
    initialFitComment = args.comment
    logging.info("Comment: " + initialFitComment)
    overview['comment'] = initialFitComment
  
  # =========================
  # = End of pre-fit setup. =
  # =========================

  run = 0
  chiSquareList = []
  for x in sorted(overview.keys()):
    print x
  overview['rerunFlag'] = True
  fullStartTime = datetime.datetime.now()
  while overview['rerunFlag'] == True:
    overview['rerunFlag'] = False
    converged = False
    run += 1
    startTime = datetime.datetime.now()
    overview[run] = {}
    overview[run]['tag'] = tag[overview['fitType']]
    if run == 1:
      overview[run]['stem'] = 'input.fort'
      shutil.copy(overview[run]['stem'] + ".13", 'fort.13')
    else:
      print "Restart: ", run
      bump(overview[run]['stem'] + ".fit.13", 'fort.13')
      overview[run]['stem'] = datetime.datetime.now().strftime("%Y-%m-%d_%H.%M.%S.%f") + overview[run]['tag']
    shutil.copy('fort.13', overview[run]['stem'] + '.fort.13')
    overview[run]['levelName'] = levelList[levelIndex]
    overview[run]['fitString'] = fitLevelDict[overview[run]['levelName']]
    print "Running..."
    proc = subprocess.Popen([overview['vpfitExecutable']], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
    result = proc.communicate(input=overview[run]['fitString'])
    runningTime = datetime.datetime.now() - startTime
    runningTimeDelta = runningTime.__str__()
    overview[run]['runningTime'] = runningTimeDelta
    print "Running time:", runningTimeDelta
    shutil.copy('fort.18', overview[run]['stem'] + '.fort.18')
    shutil.copy('fort.26', overview[run]['stem'] + '.fort.26')
    proc = subprocess.call(['fort18analysis', 'fort.18', overview[run]['stem']])
    # creates the fit.13
    cat(overview[run]['stem'] + '.fit.13', 'head.6', overview[run]['stem'] + '.finalbody.7')
    overview[run]['finalComponents'] = countLines(overview[run]['stem'] + '.finalbody.7')
    overview[run]['Ndropped'] = overview['startingComponents'] - overview[run]['finalComponents']
    with open(overview[run]['stem'] + '.analysis.p.gz', 'rb') as fp:
      overview[run]['analysis'] = pickle.loads(zlib.decompress(fp.read()))
    chiSquareList.append(float(overview[run]['analysis'][overview[run]['analysis']['iterationList'][-1]]['chi-squared']))
    status = ''
    warning = ''
    # is chisquare monotonic?
    if sorted(chiSquareList, reverse=True) == chiSquareList:
      chiSquareCheck = True
    else:
      chiSquareCheck = False
      print "inter-run chiSquareCheck failed for run: ", run
      status = "converged"
      warning += 'interrun chiSquareCheck failed; '
    if run >= overview['maxRuns']:
      status = "stop"
      warning += "max runs; "
    else:
      if overview[run]['analysis']['iterationList'][-3:] == '125':
        overview['rerunFlag'] = True
        continue
      else:
        status = "converged"
    if status == "converged": 
      if levelIndex < len(levelList) - 1:
        levelIndex += 1
        run = 0
        overview['rerunFlag'] = True
        continue
      else:
        if allowTransitiontoAlphaFit:
          allowTransitiontoAlphaFit = False
          fullRunningTime = datetime.datetime.now() - fullStartTime 
          fullRunningTimeDelta = runningTime.__str__()
          # store fullRunningTimeDelta
          fullStartTime = datetime.datetime.now()
          # send away finalfitDictionary now; fitType being normalFit
          # Switch to alpha fitting.
          overview['fitType'] = 'alphaFit'
          # convert from final fit to alpha variable.
          p3 = subprocess.call(['convert13-13da', overview[run]['stem'] + '.fit.13'])
          # increase the maxRuns by run count when switch occurred. 
          overview['maxRuns'] = overview['maxRuns'] + run
          overview['rerunFlag'] = True
          chiSquareList = [] # reset to not falsely trigger monotonic chiSquareCheck 
          continue
        else:
          status = "stop"
          print "Converged!"
          print "Warnings: ", warning
          continue
      # TODO send message to googledocs (dropbox script); spreadsheet, absorption system.
      # subprocess.call(['googledriveappend', overview['gdriveKey'], overview['sheetNumber'], overview['QSO'], overview['z_abs']]) # waits for return.
      logging.info("It took " + str(run) + " runs to converge.")
      # TODO create final fit versions named appropriately. 
      overview['finalComment'] = "It took " + str(run) + " runs to converge."
      fullRunningTime = datetime.datetime.now() - fullStartTime 
      fullRunningTimeDelta = runningTime.__str__()
      # store fullRunningTimeDelta      
      continue
    else:
      print "Did not converge after: ", run
      overview['finalComment'] = "Not converged yet. Runs before stopping: " + str(run)
      continue
  plotComparison(overview[run]['stem'])
  # send away finalfitDictionary now; fitType being whatever: normalFit; alphaFit; vchunkFit. 
  print overview['timeStamp']
  print "Program exited gracefully."
  pass

# ========================
# = Function definitions =
# ========================
def plotComparison(fileStem):
  """docstring for plotComparison"""
  if overview['noPlot'] == False: 
    proc = subprocess.Popen( ['plotfit', fileStem, 'input.fort.13', fileStem + ".fit.13"])
  pass  

def bump(inFile, outFile):
  """
  Takes inFile and bumps the values of the bvalues that have hit the limit.
  """
  if overview['bump'] == True:
    with open(inFile, 'r') as unBumped, open(outFile, 'w') as bumpFile:
      for line in unBumped.readlines():
        bumpFile.write(re.sub(r' 0.5000', ' 0.6250', line))
  else:
    shutil.copyfileobj(open(inFile, 'r'), open(outFile, 'w')) 
  pass

def cat(outfilename, *infilenames):
  """reproduces cat file1 file2... > outfilename behavior."""  
  with open(outfilename, 'w') as outFile:
    for infilename in infilenames:
      with open(infilename) as inFile:
        shutil.copyfileobj(inFile, outFile)
  
def countLines(inFile):
  lines = 0
  for line in open(inFile):
    lines += 1
  return lines
    
def logDetails(inputDict, outputDict, runNumber):
  """docstring for logDetails"""
  outputDict['key'] = inputDict['alternateKey']
  outputDict['key'] = inputDict[runNumber]['alternateKey']
  
  pass
if __name__ == '__main__':
  main()

# add fitString to each fort.13
# TODO parse the body of fort.13 and fit.13 files and report any discrepancies. 
# TODO find some way to parse things that won't change (fit results, time, date) plus things
# TODO Add LaTeX comment (or json dictionary)
# TODO auto-increment start.####.13
# TODO create a fit stop flag -- create a file touch stop after current iteration (or time). 
# TODO fix bug: if select fitLevel that isn't in the "progression" but don't select alphaFit it
# TODO Estimate stopping criteria by looking at DoF, etc.
# TODO Parse and save output of fort.18/26/comment/inputfile/output file/flags...
# TODO new function should be created to parse what is needed/wanted from any .p dictionaries found in the fit directories.
# TODO plot da/a vs. chisq. 
# TODO add scp dropbox functionality.
# TODO each run gets a dictionary?
# TODO make velocity plot (figure out how to automate or choose v=0 component to feed into fitcmp)
# absolute run number; fitType run (alpha/normal/vshift)
# -----------------------
# Higher level: physical components are the structures, the particular metals are not important. Abundance ratios are interesting.
# End-run analysis should be a separate program so can be rerun separately/repeatedly ?
# stochastic shifting of every fit variable and restart of fitting process.
# -----------------------
# data = [{"running time": runningTime}]
# json
# Parse datafile -- report/log if blind or unblind. 
# overview['alphaAlreadyFit'] = False
# with open(fitLevelDict['continueTimeStamp'][-1] + '.fit.13', 'r') as finalFit13:
#   if re.search('qa', finalFit13.read()):
#     overview['alphaAlreadyFit'] = True # If already started out fitting for alpha
# TODO touch finished
# TODO check that each finished thing the chi-squared has gone down. 
# Create a J200-200_1.6927.log.csv ln -s log.csv for each absorber -- append to it things wanted to see.
# start.000001.13 ParentComment: species used; regions used (head.00001.6) body.0000.7
# start.000001.test.00001.13 TweakComment: remove component 'ac'
# start.000001.test.00002.13 TweakComment: fitString L3
# start.000001.test.00003.13 TweakComment: fitString L4 -- probably shouldn't have a new file for different fit parameters. 
# start.000001.head.003.body.00004.13
# start.000001.test.00004.13 TweakComment: fitString L4 remove FeII 'ac'
# finished.000001.test.00002.13 TweakComment: 
# split 1 into 3 components (estimate Equivalent Width; 3 velocity components from the 1)
# remove 1 component (estimate Equivalent Width; two velocity components)
# remove component, freeze everything but 4 surrounding. 
# fd = open('document.csv','a')
# import csv
# with open('eggs.csv', 'ab') as logFile:
#   spamWriter = csv.writer(logFile)
#   spamWriter.writerow(['Spam', 'Lovely, Spam'])
# bob = csv.reader(open('eggs.csv','rb'))
#       if re.search('BAD', line):
#         logging.error(line)
#       if re.search('err', line):
#         logging.error(line)# with open('rerun.bash', 'w') as fh:
#   print >>fh, "#!/bin/bash\nexport ATOMDIR=", os.environ['ATOMDIR'], "\nexport VPFSETUP=", os.environ['VPFSETUP'], \
#     "\nexport VPFPLOTS=", os.environ['VPFPLOTS'], "\ncp ", overview['timeStamp'] + ".fort.13 fort.13", \
#     "\nprintf " + repr(currentParameterString) + " | " + overview['vpfitExecutable']
# if overview['bump']:
#   "Not bumping values. Hope this is what you want."
#   shutil.copy('input.fort.13', overview['fitDirectory'] + 'bump.13')
# else:
#   bump('input.fort.13', 'bump.13')
#   d = difflib.Differ()
#   diff = difflib.unified_diff(open('input.fort.13', 'r').read().split('\n'), open('bump.13','r').read().split('\n'), n=0)
# TODO consolidate run, overview, overview, etc. 
# with open('command.info', 'w') as fh:
#   print >>fh, "! runCommand: printf " + repr(currentParameterString) + " | " + overview['vpfitExecutable']
# # TODO put header in each iteration fort.13 